{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Lab Setup\\DataConnections\\dataConnections\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone #this below has been replaced by the below import\n",
    "from langchain_community.vectorstores import Pinecone #Importing Pinecone class, specifically using the alias PineconeStore for convenience.\n",
    "#from langchain.llms import OpenAI  #this below has been replaced by the below import\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"HUG_API_KEY\"] = os.getenv(\"HUG_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read documents\n",
    "\n",
    "def load_docs(directory):\n",
    "  loader = PyPDFDirectoryLoader(directory)\n",
    "  documents = loader.load()\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the directory to the 'load_docs' function\n",
    "\n",
    "directory = 'D:/Lab Setup/DataConnections/Docs'\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'D:\\\\Lab Setup\\\\DataConnections\\\\Docs\\\\Doc 1.pdf', 'page': 0}, page_content=\"India, officially known as the Republic of India, is a diverse and vibrant country located in South\\nAsia. With a rich history spanning thousands of years, India is known for its cultural heritage, \\nreligious diversity, and vast landscapes. From the majestic Himalayas in the north to the serene\\nbackwaters of Kerala in the south, India encompasses a wide range of geographical features, \\nincluding deserts, plains, mountains, and coastlines, making it a land of incredible natural \\nbeauty.\\nIndia is the seventh-largest country by land area and the second-most populous country in the \\nworld, with a population exceeding 1.3 billion people. It is a federal parliamentary democratic \\nrepublic, with a president as the head of state and a prime minister as the head of government. \\nThe country follows a multi-tiered administrative structure, with 28 states and 9 union territories,\\neach having its own elected government.\\nIndia has a rich cultural heritage that has evolved over thousands of years. It is home to various\\nreligions, including Hinduism, Islam, Christianity, Sikhism, Buddhism, and Jainism, among \\nothers. These religions coexist harmoniously, contributing to India's multicultural fabric. \\nFestivals like Diwali, Eid, Christmas, and Holi are celebrated with great enthusiasm and bring \\npeople from different communities together.\\nThe history of India is characterized by ancient civilizations, invasions, and the establishment of\\npowerful empires. The Indus Valley Civilization, one of the world's oldest urban civilizations, \\nflourished in the northwestern part of the Indian subcontinent around 2500 BCE. Over the \\ncenturies, India witnessed the rise and fall of several dynasties, including the Maurya, Gupta, \\nand Mughal empires. The Mughal period, in particular, left a lasting impact on Indian culture, \\nart, and architecture.\\nIndia's struggle for independence from British colonial rule is a significant chapter in its history. \\nLed by Mahatma Gandhi and other freedom fighters, the non-violent resistance movement \\ngained momentum and eventually led to India's independence on August 15, 1947. This day is \\ncelebrated annually as Independence Day.\\nIndia's economy is one of the fastest-growing in the world. It has transitioned from an agrarian \\neconomy to a service-oriented and industrialized economy. The country is known for its \\nsoftware and information technology services, pharmaceuticals, textiles, agriculture, and \\nmanufacturing sectors. Major cities like Mumbai, Delhi, Bangalore, and Chennai are hubs of \\nbusiness and commerce, attracting investments and fostering innovation.\\nDelhi is the capital of India\"),\n",
       " Document(metadata={'source': 'D:\\\\Lab Setup\\\\DataConnections\\\\Docs\\\\Doc 2.pdf', 'page': 0}, page_content=\"However, India also faces various socio-economic challenges. Poverty, income inequality, and \\nunemployment are persistent issues that the country strives to address. Efforts are being made\\nto improve education, healthcare, infrastructure, and social welfare programs to uplift \\nmarginalized sections of society.\\nEducation plays a vital role in India, with a strong emphasis on academic excellence. The \\ncountry has a vast network of schools, colleges, and universities, producing a large number of \\ngraduates every year. Indian professionals have made significant contributions in various fields \\nglobally, particularly in science, technology, engineering, and mathematics (STEM).\\nThe Indian film industry, popularly known as Bollywood, is a global phenomenon, producing the\\nlargest number of films annually. Indian cinema reflects the diversity and cultural richness of \\nthe country and has a massive following both within India and among the Indian diaspora \\nworldwide.\\nIndian cuisine is renowned for its flavors, spices, and regional specialties. Each state has its \\nown culinary traditions, offering a wide range of vegetarian and non-vegetarian dishes. Indian \\nfood has gained international popularity, with dishes like curry, biryani, dosa, and tandoori \\nbeing enjoyed by people worldwide.\\nThe Indian rupee is the official currency in the Republic of India. The rupee is subdivided into \\n100 paise. The issuance of the currency is controlled by the Reserve Bank of India.\\n₹The Indian rupee sign ( ) is the currency symbol for the Indian rupee the official currency of \\nIndia\\nTourism is a significant contributor to India's economy. The country attracts millions of visitors \\neach year who come to explore its historical sites, architectural wonders, wildlife sanctuaries, \\nand scenic landscapes. Iconic landmarks such as the Taj Mahal, Jaipur's palaces, Kerala's \\nbackwaters, and the beaches of Goa are popular tourist destinations.\\nIndia's cultural heritage is preserved in its ancient monuments and UNESCO World Heritage \\nSites. From the intricate carvings of Khajuraho temples to the majestic forts of Rajasthan, these\\narchitectural marvels reflect India's rich history and artistic traditions.\\nIndia's diversity extends to its languages as well. While Hindi and English are the official \\nlanguages at the national level, there are 22 officially recognized regional languages, including \\nBengali, Tamil, Telugu, Marathi, Urdu, Punjabi, and Gujarati, among others. This linguistic \\ndiversity is a testament to India's multicultural ethos.\\nIn recent years, India has made significant strides in space exploration. The Indian Space \\nResearch Organization (ISRO) has successfully launched satellites and missions, including the\\nMars Orbiter Mission (MOM), also known as Mangalyaan. These achievements have placed \\nIndia among the elite group of nations with advanced space programs.\"),\n",
       " Document(metadata={'source': 'D:\\\\Lab Setup\\\\DataConnections\\\\Docs\\\\Doc 2.pdf', 'page': 1}, page_content=\"India's diplomatic influence is also growing on the global stage. The country actively \\nparticipates in international forums and has strong bilateral relations with nations around the \\nworld. India is a founding member of the Non-Aligned Movement and plays an active role in \\nvarious international organizations, such as the United Nations and World Trade Organization.\\nIn conclusion, India is a vast and diverse country with a rich cultural heritage, stunning \\nlandscapes, and a rapidly growing economy. It is a nation where ancient traditions coexist with \\nmodern aspirations. Despite its challenges, India continues to evolve and leave an indelible \\nmark on the world, making it a fascinating and dynamic country to explore.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will split the documents into chunks\n",
    "\n",
    "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "docs = split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skong\\AppData\\Local\\Temp\\ipykernel_10720\\3367226509.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello Buddy\")\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.069788359105587,\n",
       " 0.05420626699924469,\n",
       " 0.07814787328243256,\n",
       " 0.033901240676641464,\n",
       " 0.024947505444288254,\n",
       " -0.0967373475432396,\n",
       " 0.05952315405011177,\n",
       " 0.058978162705898285,\n",
       " -0.01789671741425991,\n",
       " -0.023178840056061745,\n",
       " -0.019000211730599403,\n",
       " 0.0005969092599116266,\n",
       " 0.024666039273142815,\n",
       " -0.07030832022428513,\n",
       " -0.007522563450038433,\n",
       " 0.010224507190287113,\n",
       " -0.011180819943547249,\n",
       " -0.02124859392642975,\n",
       " -0.0385945588350296,\n",
       " 0.026550382375717163,\n",
       " -0.0650523379445076,\n",
       " 0.06500021368265152,\n",
       " 0.009431798942387104,\n",
       " -0.06271222978830338,\n",
       " -0.023625466972589493,\n",
       " -0.030638093128800392,\n",
       " 0.05996112897992134,\n",
       " 0.07367486506700516,\n",
       " -0.032867807894945145,\n",
       " -0.026061033830046654,\n",
       " -0.006967142224311829,\n",
       " 0.03061792254447937,\n",
       " 0.05939663201570511,\n",
       " 0.0014719826867803931,\n",
       " 0.012021631933748722,\n",
       " 0.028293736279010773,\n",
       " -0.059225261211395264,\n",
       " -0.07919756323099136,\n",
       " 0.04896372929215431,\n",
       " 0.02309011109173298,\n",
       " 0.055362798273563385,\n",
       " -0.02625139430165291,\n",
       " -0.01732112467288971,\n",
       " 0.0055111004039645195,\n",
       " 0.05862762778997421,\n",
       " -0.02973806858062744,\n",
       " 0.046267036348581314,\n",
       " 0.04452728480100632,\n",
       " 0.03799322992563248,\n",
       " -0.03244156017899513,\n",
       " -0.032030653208494186,\n",
       " -0.0745997503399849,\n",
       " -0.0991547703742981,\n",
       " 0.058602359145879745,\n",
       " 0.09203116595745087,\n",
       " 0.0721588060259819,\n",
       " -0.04752405360341072,\n",
       " 0.008467137813568115,\n",
       " 0.008853606879711151,\n",
       " -0.06717110425233841,\n",
       " -0.05602798983454704,\n",
       " 0.012392199598252773,\n",
       " -0.07076603174209595,\n",
       " -0.07935743778944016,\n",
       " 0.025537746027112007,\n",
       " -0.028746897354722023,\n",
       " -0.06868761777877808,\n",
       " 0.02878769114613533,\n",
       " -0.0375085286796093,\n",
       " -0.03945612534880638,\n",
       " -0.04507843032479286,\n",
       " 0.04845906049013138,\n",
       " 0.013318544253706932,\n",
       " 0.021408051252365112,\n",
       " -0.057900622487068176,\n",
       " -0.008303198963403702,\n",
       " 0.031046278774738312,\n",
       " 0.07448340952396393,\n",
       " 0.028353501111268997,\n",
       " -0.018620017915964127,\n",
       " -0.0409039668738842,\n",
       " -0.0701877623796463,\n",
       " -0.008551055565476418,\n",
       " -0.012738772667944431,\n",
       " 0.02206619456410408,\n",
       " -0.04596153274178505,\n",
       " -0.008397541008889675,\n",
       " 0.014853216707706451,\n",
       " 0.0027400401886552572,\n",
       " 0.03460158035159111,\n",
       " -0.09206411242485046,\n",
       " 0.08678366243839264,\n",
       " 0.09252088516950607,\n",
       " 0.019639037549495697,\n",
       " -0.05295176059007645,\n",
       " -0.04308945685625076,\n",
       " 0.07335451245307922,\n",
       " 0.01568634994328022,\n",
       " -0.13313093781471252,\n",
       " 0.18892931938171387,\n",
       " 0.07705486565828323,\n",
       " 0.07706547528505325,\n",
       " 0.02275349572300911,\n",
       " 0.0036705401726067066,\n",
       " 0.03158925846219063,\n",
       " 0.022912293672561646,\n",
       " -0.058326948434114456,\n",
       " 0.09166190773248672,\n",
       " -0.026274247094988823,\n",
       " -0.02697330340743065,\n",
       " -0.021907206624746323,\n",
       " -0.009309409186244011,\n",
       " -0.027233434841036797,\n",
       " 0.05238281935453415,\n",
       " 0.07760743796825409,\n",
       " -0.0005197332939133048,\n",
       " -0.02068084478378296,\n",
       " 0.07939454168081284,\n",
       " -0.07064998894929886,\n",
       " -0.004898622166365385,\n",
       " -0.01367795467376709,\n",
       " 0.012932968325912952,\n",
       " -0.032109037041664124,\n",
       " 0.023537002503871918,\n",
       " 0.013630013912916183,\n",
       " -0.038415081799030304,\n",
       " 0.024055296555161476,\n",
       " -4.7437140648990646e-33,\n",
       " 0.038581881672143936,\n",
       " -0.03632260113954544,\n",
       " 0.05680444836616516,\n",
       " 0.20758983492851257,\n",
       " -0.06085404008626938,\n",
       " 0.009389531798660755,\n",
       " -0.03535956144332886,\n",
       " -0.019329851493239403,\n",
       " 0.004193523433059454,\n",
       " 0.001778300735168159,\n",
       " 0.06255526095628738,\n",
       " 0.07132024317979813,\n",
       " -0.053475409746170044,\n",
       " 0.04272277280688286,\n",
       " 0.02645346336066723,\n",
       " 0.058901261538267136,\n",
       " -0.10570615530014038,\n",
       " 0.06490790843963623,\n",
       " 0.04039429873228073,\n",
       " 0.009129785932600498,\n",
       " -0.06505542993545532,\n",
       " -0.04786781594157219,\n",
       " 0.000609919021371752,\n",
       " 0.04792136326432228,\n",
       " 0.022530516609549522,\n",
       " 0.00027935366961173713,\n",
       " 0.04671046510338783,\n",
       " -0.0815335363149643,\n",
       " 0.02717881090939045,\n",
       " 0.04208612069487572,\n",
       " -0.05766581371426582,\n",
       " -0.028443066403269768,\n",
       " 0.025674039497971535,\n",
       " 0.037457019090652466,\n",
       " -0.013693642802536488,\n",
       " 0.005312067456543446,\n",
       " 0.06007678806781769,\n",
       " -0.06595907360315323,\n",
       " -0.08369918912649155,\n",
       " -0.03458143770694733,\n",
       " -0.030660798773169518,\n",
       " 0.04927722364664078,\n",
       " -0.01787114515900612,\n",
       " 0.00861898623406887,\n",
       " 0.03906624764204025,\n",
       " -0.027273481711745262,\n",
       " 0.01642768830060959,\n",
       " 0.012519610114395618,\n",
       " -0.010824021883308887,\n",
       " -0.0069543966092169285,\n",
       " -0.02858663909137249,\n",
       " 0.040284477174282074,\n",
       " -0.059778276830911636,\n",
       " 0.07012257725000381,\n",
       " -0.06822274625301361,\n",
       " -0.03562340885400772,\n",
       " 0.03436654433608055,\n",
       " 0.007559789344668388,\n",
       " -0.005428625270724297,\n",
       " -0.013946511782705784,\n",
       " 0.019693749025464058,\n",
       " 0.11176680028438568,\n",
       " -0.031078003346920013,\n",
       " -0.010961012914776802,\n",
       " -0.06446173042058945,\n",
       " -0.016045769676566124,\n",
       " 0.0866411030292511,\n",
       " -0.030396495014429092,\n",
       " 0.04842614382505417,\n",
       " -0.06848315894603729,\n",
       " 0.0029434741009026766,\n",
       " 0.01699366606771946,\n",
       " 0.03442339226603508,\n",
       " -0.05967586487531662,\n",
       " 0.014415587298572063,\n",
       " 0.053367022424936295,\n",
       " -0.005778992082923651,\n",
       " -0.07200734317302704,\n",
       " 0.012998681515455246,\n",
       " -0.007748784497380257,\n",
       " 0.013700474053621292,\n",
       " 0.011358408257365227,\n",
       " -0.0077657983638346195,\n",
       " -0.037887804210186005,\n",
       " 0.06661553680896759,\n",
       " 0.06453313678503036,\n",
       " 0.006028845440596342,\n",
       " -0.06192987039685249,\n",
       " -0.05701630562543869,\n",
       " -0.09005864709615707,\n",
       " -0.14298102259635925,\n",
       " 0.0203452967107296,\n",
       " 0.028676189482212067,\n",
       " 0.032465510070323944,\n",
       " -0.032605428248643875,\n",
       " 3.44050262020192e-33,\n",
       " 0.09627881646156311,\n",
       " 0.044487230479717255,\n",
       " -0.04238714650273323,\n",
       " -0.053365424275398254,\n",
       " -0.012616913765668869,\n",
       " -0.0012779459357261658,\n",
       " -0.04644673317670822,\n",
       " 0.07411836832761765,\n",
       " -0.12352927029132843,\n",
       " -0.007119515910744667,\n",
       " -0.008699094876646996,\n",
       " -0.0507158599793911,\n",
       " 0.08202648162841797,\n",
       " -0.010096346028149128,\n",
       " 0.04455673322081566,\n",
       " 0.09078025817871094,\n",
       " 0.06065204367041588,\n",
       " 0.03783895820379257,\n",
       " -0.017835937440395355,\n",
       " -0.02245474047958851,\n",
       " -0.06918349862098694,\n",
       " -0.016655752435326576,\n",
       " -0.02650979533791542,\n",
       " 0.025623004883527756,\n",
       " -0.06020238623023033,\n",
       " -0.009123269468545914,\n",
       " 0.0030174662824720144,\n",
       " 0.0015857903053984046,\n",
       " -0.07711774110794067,\n",
       " -0.06069722771644592,\n",
       " 0.10801774263381958,\n",
       " 0.017874641343951225,\n",
       " -0.05322751775383949,\n",
       " 0.02397783100605011,\n",
       " -0.0135950380936265,\n",
       " 0.09174276143312454,\n",
       " 0.028409475460648537,\n",
       " -0.04773016646504402,\n",
       " -0.011409730650484562,\n",
       " -0.11023158580064774,\n",
       " -0.047754161059856415,\n",
       " 0.03513936325907707,\n",
       " -0.05509571358561516,\n",
       " 0.029237544164061546,\n",
       " -0.019759299233555794,\n",
       " -0.058055583387613297,\n",
       " 0.09778168052434921,\n",
       " 0.008509302511811256,\n",
       " -0.02062133140861988,\n",
       " 0.017003018409013748,\n",
       " -0.1062241867184639,\n",
       " 0.005269600544124842,\n",
       " -0.011264331638813019,\n",
       " -0.040617939084768295,\n",
       " -0.05481632426381111,\n",
       " -0.04439367726445198,\n",
       " -0.025697290897369385,\n",
       " 0.035832636058330536,\n",
       " -0.031414031982421875,\n",
       " -0.013334543444216251,\n",
       " 0.05045571178197861,\n",
       " 0.10049016028642654,\n",
       " 0.029927443712949753,\n",
       " 0.0795096904039383,\n",
       " 0.018311964347958565,\n",
       " 0.056592535227537155,\n",
       " -0.04968113452196121,\n",
       " 0.016870666295289993,\n",
       " -0.02303866669535637,\n",
       " -0.0476272776722908,\n",
       " 0.00808024127036333,\n",
       " 0.055618979036808014,\n",
       " 0.028933005407452583,\n",
       " 0.030480751767754555,\n",
       " -0.004192342981696129,\n",
       " -0.01933624967932701,\n",
       " 0.06739480793476105,\n",
       " 0.004616985097527504,\n",
       " -0.02775653451681137,\n",
       " 0.05167409032583237,\n",
       " -0.024105660617351532,\n",
       " 0.015811000019311905,\n",
       " 0.040824417024850845,\n",
       " 0.06979387998580933,\n",
       " -0.06612455099821091,\n",
       " -0.017000863328576088,\n",
       " 0.0701327696442604,\n",
       " 0.07647687941789627,\n",
       " 0.0033459714613854885,\n",
       " -0.015093875117599964,\n",
       " 0.0009143674978986382,\n",
       " 0.004818746820092201,\n",
       " -0.1037110760807991,\n",
       " 0.018684757873415947,\n",
       " -0.0227736197412014,\n",
       " -1.6008881331686098e-08,\n",
       " -0.03379509598016739,\n",
       " 0.059855397790670395,\n",
       " -0.036355309188365936,\n",
       " 0.06778041273355484,\n",
       " 0.05005522072315216,\n",
       " 0.06447288393974304,\n",
       " -0.08214758336544037,\n",
       " -0.027982143685221672,\n",
       " 0.05528416484594345,\n",
       " 0.04399855434894562,\n",
       " 0.07301624119281769,\n",
       " 0.029532339423894882,\n",
       " -0.06715996563434601,\n",
       " 0.024248210713267326,\n",
       " 0.08193706721067429,\n",
       " 0.061403896659612656,\n",
       " -0.05148819088935852,\n",
       " -0.011589900590479374,\n",
       " -0.04694133996963501,\n",
       " -0.06341458112001419,\n",
       " -0.032487086951732635,\n",
       " 0.02297552488744259,\n",
       " 0.052110858261585236,\n",
       " -0.026350121945142746,\n",
       " -0.0012115715071558952,\n",
       " 0.007197774481028318,\n",
       " -0.06705574691295624,\n",
       " 0.042921874672174454,\n",
       " -0.02323417365550995,\n",
       " -0.04127392917871475,\n",
       " 0.0023701402824372053,\n",
       " 0.13688527047634125,\n",
       " -0.01910625398159027,\n",
       " -0.008777688257396221,\n",
       " 0.000923596671782434,\n",
       " -0.02322498895227909,\n",
       " 0.04884273186326027,\n",
       " 0.04468472674489021,\n",
       " 0.04295491427183151,\n",
       " 0.02351197972893715,\n",
       " -0.05564107745885849,\n",
       " -0.014923283830285072,\n",
       " -0.02307853475213051,\n",
       " -0.09206119924783707,\n",
       " -0.01942514441907406,\n",
       " 0.04348471760749817,\n",
       " 0.08746954053640366,\n",
       " -0.10251273214817047,\n",
       " 0.006790034472942352,\n",
       " -0.07210742682218552,\n",
       " -0.055342428386211395,\n",
       " 0.03467114269733429,\n",
       " 0.03941791132092476,\n",
       " 0.06323447078466415,\n",
       " 0.06754031777381897,\n",
       " 0.05118653178215027,\n",
       " 0.0019086457323282957,\n",
       " 0.0001587745064171031,\n",
       " -0.0571918860077858,\n",
       " -0.0230877585709095,\n",
       " 0.04198142886161804,\n",
       " 0.08144471794366837,\n",
       " 0.020753901451826096,\n",
       " -0.005565055646002293]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pinecone allows for data to be uploaded into a vector database and true semantic search can be performed.**\n",
    "**Not only is conversational data highly unstructured, but it can also be complex. Vector search and vector databases allows for similarity searches.**\n",
    "\n",
    "**We will initialize Pinecone and create a Pinecone index by passing our documents, embeddings model and mentioning the specific INDEX which has to be used**\n",
    "**Vector databases are designed to handle the unique structure of vector embeddings, which are dense vectors of numbers that represent text. They are used in machine learning to capture the meaning of words and map their semantic meaning.**\n",
    "\n",
    "**These databases index vectors for easy search and retrieval by comparing values and finding those that are most similar to one another, making them ideal for natural language processing and AI-driven applications.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to recent changes from Pinecone team, there are some minor changes we have to implement, as a part of this we Initialize the Pinecone client\n",
    "# Please update your pinecone-client package version >=3.0.1\n",
    "\n",
    "from pinecone import Pinecone as PineconeClient # Importing the Pinecone class from the pinecone package\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "\n",
    "# Set your Pinecone API key\n",
    "# Recent changes by langchain team, expects \"\"PINECONE_API_KEY\" environment variable for Pinecone usage! So we are creating it here\n",
    "# we are setting the environment variable \"PINECONE_API_KEY\" to the value and in the next step retrieving it :)\n",
    "\n",
    "# Initialize the Pinecone client\n",
    "PineconeClient(api_key = os.getenv(\"PINECONE_API_KEY\"), environment=\"gcp-starter\")\n",
    "index_name=\"dataconnections\"\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name = index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will help us in fetching the top relevent documents from our vector store - Pinecone\n",
    "\n",
    "def get_similiar_docs(query, k=2):\n",
    "    similar_docs = index.similarity_search(query, k=k)\n",
    "    return similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'load_qa_chain' Loads a chain that you can use to do QA over a set of documents.**\n",
    "\n",
    "**And we will be using Huggingface for the reasoning purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "#from langchain.llms import HuggingFaceHub\n",
    "#The above have been updated recently, so going forward we have to use the below :)\n",
    "\n",
    "from langchain.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based large language model.**\n",
    "\n",
    "**It was created by over 1000 AI researchers to provide a free large language model for everyone who wants to try. Trained on around 366 billion tokens over March through July 2022, it is considered an alternative to OpenAI's GPT-3 with its 176 billion parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The earlier mentioned 'HuggingFaceHub' class has been depreciated, so please use the below class'HuggingFaceEndpoint' \n",
    "# and the below mentioned model outperforms most of the available open source LLMs\n",
    "\n",
    "# llm = HuggingFaceEndpoint(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\") # Model link : https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different Types Of Chain_Type:**\n",
    "\n",
    "**\"map_reduce\": It divides the texts into batches, processes each batch separately with the question, and combines the answers to provide the final answer.**\n",
    "\n",
    "**\"refine\": It divides the texts into batches and refines the answer by sequentially processing each batch with the previous answer.**\n",
    "\n",
    "**\"map-rerank\": It divides the texts into batches, evaluates the quality of each answer from LLM, and selects the highest-scoring answers from the batches to generate the final answer. These alternatives help handle token limitations and improve the effectiveness of the question-answering process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skong\\AppData\\Local\\Temp\\ipykernel_10720\\1148363849.py:1: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/v0.2/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/v0.2/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will help us get the answer to the question that we raise\n",
    "\n",
    "def get_answer(query):\n",
    "  relevant_docs = get_similiar_docs(query)\n",
    "  print(relevant_docs)\n",
    "  response = chain.run(input_documents=relevant_docs, question=query)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing our question to the above created function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 0.0, 'source': 'D:\\\\Lab Setup\\\\DataConnections\\\\Docs\\\\Doc 2.pdf'}, page_content='However, India also faces various socio-economic challenges. Poverty, income inequality, and \\nunemployment are persistent issues that the country strives to address. Efforts are being made\\nto improve education, healthcare, infrastructure, and social welfare programs to uplift \\nmarginalized sections of society.\\nEducation plays a vital role in India, with a strong emphasis on academic excellence. The \\ncountry has a vast network of schools, colleges, and universities, producing a large number of \\ngraduates every year. Indian professionals have made significant contributions in various fields \\nglobally, particularly in science, technology, engineering, and mathematics (STEM).\\nThe Indian film industry, popularly known as Bollywood, is a global phenomenon, producing the\\nlargest number of films annually. Indian cinema reflects the diversity and cultural richness of \\nthe country and has a massive following both within India and among the Indian diaspora \\nworldwide.'), Document(metadata={'page': 0.0, 'source': 'D:\\\\Lab Setup\\\\DataConnections\\\\Docs\\\\Doc 2.pdf'}, page_content='However, India also faces various socio-economic challenges. Poverty, income inequality, and \\nunemployment are persistent issues that the country strives to address. Efforts are being made\\nto improve education, healthcare, infrastructure, and social welfare programs to uplift \\nmarginalized sections of society.\\nEducation plays a vital role in India, with a strong emphasis on academic excellence. The \\ncountry has a vast network of schools, colleges, and universities, producing a large number of \\ngraduates every year. Indian professionals have made significant contributions in various fields \\nglobally, particularly in science, technology, engineering, and mathematics (STEM).\\nThe Indian film industry, popularly known as Bollywood, is a global phenomenon, producing the\\nlargest number of films annually. Indian cinema reflects the diversity and cultural richness of \\nthe country and has a massive following both within India and among the Indian diaspora \\nworldwide.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skong\\AppData\\Local\\Temp\\ipykernel_10720\\2884257595.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = chain.run(input_documents=relevant_docs, question=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It is facing various socio-economic challenges, such as poverty, income inequality, and unemployment. However, efforts are being made to improve education, healthcare, infrastructure, and social welfare programs.\n"
     ]
    }
   ],
   "source": [
    "our_query = \"How is India's economy?\"\n",
    "answer = get_answer(our_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI # this has been replaced by the below import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='question', description='Question generated from provided input text data.', type='string'), ResponseSchema(name='choices', description='Available options for a multiple-choice question in comma separated.', type='string'), ResponseSchema(name='answer', description='Correct answer for the asked question.', type='string')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"question\", description=\"Question generated from provided input text data.\"),\n",
    "    ResponseSchema(name=\"choices\", description=\"Available options for a multiple-choice question in comma separated.\"),\n",
    "    ResponseSchema(name=\"answer\", description=\"Correct answer for the asked question.\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This helps us fetch the instructions the langchain creates to fetch the response in desired format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"question\": string  // Question generated from provided input text data.\n",
      "\t\"choices\": string  // Available options for a multiple-choice question in comma separated.\n",
      "\t\"answer\": string  // Correct answer for the asked question.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    " \n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ChatGPT object\n",
    "\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000001EC71456310>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000001EC713CB130>, root_client=<openai.OpenAI object at 0x000001EC713B1580>, root_async_client=<openai.AsyncOpenAI object at 0x000001EC71456370>, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The below snippet will give out a string that contains instructions for how the response should be formatted, and we then insert that into our prompt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"When a text input is given by the user, please generate multiple choice questions \n",
    "        from it along with the correct answer. \n",
    "        \\n{format_instructions}\\n{user_prompt}\"\"\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='When a text input is given by the user, please generate multiple choice questions \\n        from it along with the correct answer. \\n        \\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"question\": string  // Question generated from provided input text data.\\n\\t\"choices\": string  // Available options for a multiple-choice question in comma separated.\\n\\t\"answer\": string  // Correct answer for the asked question.\\n}\\n```\\n It is facing various socio-economic challenges, such as poverty, income inequality, and unemployment. However, efforts are being made to improve education, healthcare, infrastructure, and social welfare programs.')]\n"
     ]
    }
   ],
   "source": [
    "final_query = prompt.format_prompt(user_prompt = answer)\n",
    "print(final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='When a text input is given by the user, please generate multiple choice questions \\n        from it along with the correct answer. \\n        \\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"question\": string  // Question generated from provided input text data.\\n\\t\"choices\": string  // Available options for a multiple-choice question in comma separated.\\n\\t\"answer\": string  // Correct answer for the asked question.\\n}\\n```\\n It is facing various socio-economic challenges, such as poverty, income inequality, and unemployment. However, efforts are being made to improve education, healthcare, infrastructure, and social welfare programs.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_query.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"question\": \"What are some of the socio-economic challenges faced by the country?\",\n",
      "\t\"choices\": \"A. Poverty, B. Income inequality, C. Unemployment, D. All of the above\",\n",
      "\t\"answer\": \"D. All of the above\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "final_query_output = chat_model.invoke(final_query.to_messages())\n",
    "print(final_query_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While working with scenarios like above where we have to process multi-line strings(separated by newline characters – ‘\\n’). In such situations, we use re.DOTALL.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract JSON data from Markdown text that we have\n",
    "\n",
    "markdown_text = final_query_output.content\n",
    "json_string = re.search(r'{(.*?)}', markdown_text, re.DOTALL).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\"question\": \"What are some of the socio-economic challenges faced by the country?\",\n",
      "\t\"choices\": \"A. Poverty, B. Income inequality, C. Unemployment, D. All of the above\",\n",
      "\t\"answer\": \"D. All of the above\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
